Lerneinheit 4
---

Die zwei Hauptthemen des Blocks vom 5. Juni 2020 waren MarcEdit und VuFind. Angefangen haben wir jedoch mit OpenRefine.

OpenRefine ist eine Desktop-Applikation, die den Browser (egal welchen, einfach den, den man öfters benutzt) als eine grafische Oberfläche nutzt. Man kann es am besten gebrauchen, wenn man tabellenartige Formate hat, wie z.B. csv oder tsv. Die Applikation ist eine gute Hilfe bei Überblicks-Verschaffung von Datensätzen, Auflösung von Inkonsistenzen in einem Datensatz oder Hinzufügen von weiteren Datenquellen in einen Datensatz usw. (Quelle: https://librarycarpentry.org/lc-open-refine/01-introduction/index.html)
Als Hausaufgabe sollten wir die Library Carpentry Lessons bearbeiten. Bei der Installation hatte ich zunächst ein kleines Problem, da mein Laptop die Anwendung (openrefine.exe) als eine Bedrohung sah. Glücklicherweise gab es dann aber doch einen Batton, sodass man die Meldung ignorieren konnte und ich konnte fast vorfahren. Es kam nämlich ein Fenster, dass ich noch die Java-Software von Oracle installieren muss, falls ich OpenRefine installieren möchte. Habe ich dann auch gemacht, obwohl ich es etwas nervig fand, dass ich Sachen auf meinem Computer installieren muss ohne zu wissen warum. Sobald aber OpenRefine startbereit war, fing ich mit der ersten Aufgabe an: Import einer csv-Datei. Da ich in etwa drei Stunden für das Tutorial gebraucht habe, möchte ich hier nicht jeden Schritt einzeln aufschreiben. Was mir ziemlich früh aufgefallen ist: Die Anwendung lässt vieles mit sich machen. Ich konnte bspw. alle grossgeschriebenen Titel in klein-/grossgeschriebene (Bsp. LITTLE WOMEN in Little Women) umwandeln. Für mich wäre es nicht selbstverständlich, dass sowas möglich sein könnte. Deshalb finde ich es toll, dass solche Zusatz-Einstellungen verfügbar sind. Grundsätzlich fand ich das Tutorial gut nachvollziehbar und auch die Schritte waren gut verständlich. Ich finde nur, dass es ein etwas sehr umfrangreiches Tutotrial ist (mit viel Text etc.). Man muss auch etwas bedenken, dass meine Klasse die Systeme zwar kennenlernen soll, jedoch wissen wir nicht, ob wir jemals mit einem dieser Systeme arbeiten werden und wann. Dementsprechen finde ich ein vierstündiges Tutorial etwas sehr umfangreich. Eine Kürzung des Tutorials bis auf die wichtigsten Inhalte/Schritte wäre besser. Ansonsten fand ich die Applikation selbst sehr angenehm: es gibt keine versteckten Einstellungen, sondern alles ist gut sichtbar/findbar. Ausserdem gefällt mir die Idee, dass man solche unorganisierte und unübersichtliche Dateien in die Applikation einfügen kann und somit eine sehr übersichtliche Einsicht über die Daten bekommt. Zusätzlich kann man sich selbst einstellen, welche Reihen wie geordnet werden sollten (z.B. ist mir das Verlag wichtiger als die URL, also stelle ich sie weiter vorne). Die einzige Kritik: es gibt natürlich einige wenige Einstellungen, die man vornehmen kann, die etwas mehr Kenntnisse benötigen. Z.B. kann man eine "Expression" wie diese "value.contains(",").toString()" einstellen. Ohne das Tutorial hätte ich nicht gewusst, wie die Syntax einer solchen Expression ist und woher ich die einzelnen Begriffe dafür nehme. Wahrscheinlich weisst man mit der Übung aber wie diese Expressions verwendet werden können, dafür braucht es nur mehr Training mit der App. Ansonsten: Die App bekommt von mir 8/10 Punkten!

Die Haupteinsatzmöglichkeiten von OpenRefine sind: Exploration von Datenlieferungen, Vereinheitlichung und Bereinigung undAbgleich mit Normdaten in Wikidata, GND und VIAF.

Nun kommen wir zu MarcEdit, was eine Software für das Editieren von MARC-Datensätzen ist (https://librarycarpentry.org/lc-marcedit/01-introduction/index.html). Hierzu haben wir ebenfalls eine Hausaufgabe bekommen: das Tutorial Library Carpentry Lesson zu MarcEdit. Im Vergleich zur vorherigen Hausaufgabe war das Tutorial zu MarcEdit etwas weniger umfangreich. Grundsätzlich beinhaltete es alle nötigsten Erklärungen zu den möglichen Funktionen. So wie im Tutorial beschrieben, fand ich die Software ebenfalls gut verständlich. Leider fehlt mir dabei so ziemlich der Bezug dazu, wie die Software im echten Leben wirklich verwendet wird: Brauchen es Bibliotheken zur Konvertierung verschiedener Formate? Oder ist die Anwendung etwas anders?... Diese Frage bleibt noch offen... Während dem Unterricht haben wir ebenfalls eine Gruppenarbeit dazu bekommen und zwar sollten wir XLS-Transformationen bzw. Crosswalks vornehmen. Crosswalks werden zur Konvertierung vone einem Metadatenbestand in einen anderen verwendet. So kann man beispielsweise MARC21 zu DublinCore umkonvertieren. Crosswalks beinhalten auch Regeln, z.B. wie Elemente zugeordnet werden müssen. Dabei ist meist eine 1:1-Konvertierung eigentlich unmöglich. Ausserdem ist ein XSLT eine Programmiersprache zur Transformation von XML-Dokumenten. Die Aufgabe ging wie folgend:

Nach Start des Programms wählt man den Icon "MARC Tools" aus.
Somit bekommt man ein Fenster, wo man eine Datei zum Öffnen auswählen kann und deren Speicherort angeben muss. Herr Lohmeier hat uns dabei eine spezielle Datei bereits zur Verfügung gestellt, sodass diese nun geöffnet werden konnte und ich habe sie auf dem Desktop abspeichern wollen.
Oberhalb dieser beiden Felder befindet sich auch das Feld "Select Operation", in dem man auswählen kann, von welchem Format in welchen man die Datei konvertieren möchte. Ich wähle hier bspw. MARC zu JSON.
Auch habe ich das Kästchen Translate to UTF-8 angekreuzt (obwohl ich mir nicht sicher bin, ob das etwas gebracht hat).
Sobald man auf "Execute" (oben rechts) klickt, wird die Datei nun im neuen Format auf meinem Desktop gespeichert und dort konnte ich sie auch aufrufen. Bei der Übung selbst habe ich folgende Formate ausprobiert:
MARC –> JSON
MARC –> DublinCore
MARC21 –> MARC21XML
Als nächstes haben wir uns weiter etwas Theorie angeschaut: Schnittstellen SRU, OAI-PMH und Z39.50 Im Bibliotheks- sowie Archivbereich gibt es viele Übertragungsrpotokolle, die verwendet werden. Die am besten verbreitet sind: SRU (Search/Retrieve via URL (von der Library of Congress)), OAI-PMH (Open Archives Initiative Protocol for Metadata Harvesting (von Open Archives Initiative)) und Z39.50 (von der Library of Congress). Z39.50 und SRU werden eher für Live-Abfragen oder gezielten Datenabruf mit vielen Parametern geeignet, wobei OAI-PMH bei grösseren Datenabzügen und regelmässigen Aktualisierungen zum Einsatz kommt. Bei SRU und OAI-PMH werden die Anfragen mittels URL genertiert und sind daher direkt im Browser abrufbar. Dazu haben wir ebenfalls eine Aufgabe bekommen. Wir sollten uns die Dokumentation zur SRU-Schnittstelle von der Swissbib durchlesen und eine Abfrage mit den Parametern "Katalog der Bibliothek der FH Graubünden", "Suche über alle Felder nach Suchbegriff: open" und "Format:MARC XML - swissbib" stellen. Das sah wie folgt aus:

Auf der Webseite https://sru.swissbib.ch/sru/form muss man im ersten Feld oben links "dc.possessinginstitution" anstatt "dc.id" auswählen. Als "value" (weiter rechts) gibt man den Code für die FH Graubünden ein, der E27 wäre.
Im nächsten Feld wählt man "dc.anywhere" anstatt "dc.id" aus und gibt unter "value" "open" ein.
Der letzte Parameter "Format: MARC XML - swissbib" ist bereits eingestellt unter "RecordSchema".
Wenn man auf SubmitQuery klickt bekommt man dann 1146 Treffer. Die zweite und dritte Aufgabe habe ich dann nicht mehr gemacht..
Danach befassten wir uns mit ein paar Tools zur Metadatentransformation (Catmandu (Perl), Metafacture (Java) und OAI harvester für die Kommandozeile) sowie mit der Nutzung von JSON-APIs (z.B. lobid-gnd oder dem Tool ScrAPIr).

Auch haben wir kurz die Hausaufgaben zu Solr besprochen. Solr ist eine Software, die für grosse Suchfunktionen verwendet wird (https://www.bigdata-insider.de/was-ist-solr-a-728279/). Ich persösnlich fand die Hausaufgabe wenig angenehm... Die ersten Probleme stellten sich bei der Installation. Nachdem ich die Datei heruntergeladen habe, musste ich etwas damit kämpfen, wie ich diese richtig installieren kann. Das liegt aber in meiner Schuld, da ich selbst ein bisschen verwirrt war, wie ich die Datei per Terminal installieren kann. Als es die Installation dann erfolgreich war, habe ich gemerkt, dass die einzelnen Schritte, die im Tutorial beschrieben werden, sehr sorgfältig bearbeitet werden müssen, um ein richtiges Ergebnis zu erhalten. Ausserdem musste man oft zwischen dem Browser und Terminal wechseln, sodass ich manchmal den Überblick verlor, für was ich welche Aufgabe mache bzw. welche Auswirkung sie hat. Gegen den Schluss war mir das Tutorial etwas zu mühsam geworden und ich habe frühzeitig abgebrochen.

Nun zur nächsten Aufgabe: VuFind. Wir sollten während dem Unterricht das Program "VuFind" auf unserer virutellen Maschine installieren. Bisher waren solche Installationen nicht gross problematisch, jedoch war diese Installation mehr als kompliziert. Obowhl wir eine ziemlich genaue Anleitung mit allen Codes zur Eingabe im Terminal bekommen haben, war die Installation nur bei einigen Personen von Anfang an erfolgreich. Bei mir gab es das Problem, dass obwohl ich alle Codes der Reihe nach und geduldig eingegeben hab, wollte das System nicht alle Archive herunterladen, sodass die Installation nur teilweise erfolgreich war. Aufgrund der fehlenden Archive war auch der Start des Programms nicht möglich. Ich habe mehrmals versucht, die gleichen Codes neu einzugeben, jedoch brachte das keinen Erfolg (war ich vermutet habe, jedoch trotzdem ausprobieren wollte, ob etwas besser gehen würde). "Dank" der Probleme, die auch andere Studierenden hatten, haben sich einige Lösungsmöglichkeiten entwickelt, die ich ebenfalls zu anwenden versucht habe. Kein Erfolg. Da Herr Lohmeier auch sehr mit den Problemen anderer Personen beschäftigt war, konnte ich nicht direkt Hilfe holen (die Gruppenmitglieder wussten auch nicht weiter) und so endete auch schon das Abenteuer mit VuFind. Wir haben uns die Ergebnisse anderer Gruppen trotzdem noch angeschaut bzw. klärten Fragen auf, jedoch war das weniger hilfreich, als wenn ich die Möglichkeit gehabt hätte, das System selbst auszuprobieren.

Nach einem kleinen Marktüberblick über die Discovery-Systeme beendeten wir auch schon den Block 4.
